{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-4 layers\n",
    "\n",
    "The deep learning model usually consists of various layers.\n",
    "\n",
    "tf.keras.layers contains a large amount of models with various functions, such as:\n",
    "\n",
    "`layers.Dense`, `layers.Flatten`, `layers.Input`, `layers.DenseFeature`, `layers.Dropout`\n",
    "\n",
    "`layers.Conv2D`, `layers.MaxPooling2D`, `layers.Conv1D`\n",
    "\n",
    "`layers.Embedding`, `layers.GRU`, `layers.LSTM`, `layers.Bidirectional`, etc.\n",
    "\n",
    "In case these pre-defined layers are insufficient for modeling, the users are able to write anonymous layer `tf.keras.Lambda` or write customized layer through inheriting `tf.keras.layers.Layer`.\n",
    "\n",
    "Note that `tf.keras.Lambda` is only for the layers without any trainable parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pre-defined Layer\n",
    "\n",
    "\n",
    "Here are the introductions for the most popular layers.\n",
    "\n",
    "**Fundamental layers**\n",
    "\n",
    "* Dense: Densely connected layer. # of parameters = # of features of the input layer × # of weight + # of bias.\n",
    "\n",
    "* Activation: Activation function layer. Usually placed after the Dense layer for specify the activation function in the Dense layer.\n",
    "\n",
    "* Dropout: Dropout layer. Setting the inputs as zero randomly during the training stage, which is a method of regularization.\n",
    "\n",
    "* BatchNormalization:Layer for batch normalization. It scale and translate the batches into stable mean and standad deviation through linear transformation. This lead to the model adaptive to the various distribution of the input, which is mild regularization that accelerates training. This layer is usually applied before the activation function.\n",
    "\n",
    "* SpatialDropout2D:Spatial dropout layer. Setting the whole feature map into zero with certain possibilities during training, which is a regularization to avoid high correlation between feature maps.\n",
    "\n",
    "* Input:Input layer. Usually it is the first layer when modelling through functional API.\n",
    "\n",
    "* DenseFeature:Layer that provides connection to the feature columns, which is used to accept a list of feature columns and generate a densely connected layer.\n",
    "\n",
    "* Flatten:Flatten layer, used for flattening multi-dimensional tensor into one-dimension.\n",
    "\n",
    "* Reshape:Reshape layer, reform the shape of the input tensor.\n",
    "\n",
    "* Concatenate:Concatenating layer to link multiple tensors along the specific dimension.\n",
    "\n",
    "* Add: Adding layer.\n",
    "\n",
    "* Subtract: Subtracting layer.\n",
    "\n",
    "* Maximum: Layer for maximum value.\n",
    "\n",
    "* Minimum: Layer for minimum value.\n",
    "\n",
    "\n",
    "**Layers for the convoelutional network.**\n",
    "\n",
    "* `Conv1D`: Layer of 1D convolution, ususlly for text. # of parameters = # of input channels × # of kernel size (e.g. 3) × # of kernels.\n",
    "\n",
    "* `Conv2D`: Layer of 2D convolution, ususlly for image. # of parameters = # of input channels × # of kernel size (e.g. 3×3) × # of kernels.\n",
    "\n",
    "* `Conv3D`: Layer of 3D convolution, ususlly for video. # of parameters = # of input channels × # of kernel size (e.g. 3×3×3) × # of kernels.\n",
    "\n",
    "* `SeparableConv2D`: Depthwise 2D separable covolution. Unlike the traditional convolution, separable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. # of parameters = # of input channels × size of convolutional kernel + # of input channels × 1 × 1 × # of output channels. Usually, depthwise separable convolution has a much smaller number of parameters with a better performance.\n",
    "\n",
    "* `DepthwiseConv2D`: Depthwise 2D convolution. Depthwise convolutions consists in performing just the first step in a depthwise separable convolution (which acts on each input channel separately). Usually the # of input and output channels are the same, but can be altered through the `depth_multiplier` argument to control how many output channels are generated per input channel in the depthwise step. # of output channles =  # of input channles × depth_multiplier. # of parameters = # of input channels × size of kernel × `depth_multiplier`.\n",
    "\n",
    "* `Conv2DTranspose`:2D Transposed convolution layer (sometimes called Deconvolution), but this is not the inverse operation of convolution. When the kernal maintains the same as convolution, and given the input size the same as the output size of convolution, then the output size of the transposed convolution is the same as the input size of convolution.\n",
    "\n",
    "* `LocallyConnected2D`: Locally-connected layer for 2D inputs. This layer works similarly to the `Conv2D` layer, except that weights are unshared, thus has much more parameters than `Conv2D`.\n",
    "\n",
    "* `MaxPooling2D`: 2D max pooling layer, also called down-sampling layer. This layer is for reducing dimension without any trainable prameter.\n",
    "\n",
    "* `AveragePooling2D`: 2D average pooling layer.\n",
    "\n",
    "* `GlobalMaxPool2D`: Global max pooling layer. Only one value preserved for each channel, usually used between convolution layer and fully connected layer, which is a substitution of `Flatten`.\n",
    "\n",
    "* `GlobalAvgPool2D`: Global average pooling layer. Only one value preserved for each channel.\n",
    "\n",
    "\n",
    "**Recursive network related layers**\n",
    "\n",
    "* `Embedding`: Embedding layer, provides an encoding with higher efficiency than one-hot for discrete features. It is usually used for projecting input words into dense vectors. Training is required for the parameters in the embedding layer.\n",
    "\n",
    "* `LSTM`: Long Short-Term Memory layer, which is the most popular layer for the recursive network. It contains carry track and is composed of a cell, an input gate, an output gate and a forget gate, which significantly alleviate the problem of gradient vanishing and thus applicable for the problem of long-term dependency. All the middle results could be observed when the patameter `return_sequences` is set as `True`; in the opposite case only the final result is returned.\n",
    "\n",
    "* `GRU`: Gated Recursive Unit Layer, a simplified version of LSTM without carry track, thus has less parameters and could be trained faster.\n",
    "\n",
    "* `SimpleRNN`: Simple Recursive Neural Network layer. It is not popular due to the problem of gradient vanishing, which made it inapplicable to the long-dependence.\n",
    "\n",
    "* `ConvLSTM2D`: Convolutional LSTM layer. Has similar structure to LSTM but the conversion operation to both input and status are convolution.\n",
    "\n",
    "* `Bidirectional`: Bi-directional wrapper for RNNs, for wrapping layers (such as LSTM and GRU) into bi-directional RNN, enhancing the capability of feature extraction.\n",
    "\n",
    "* `RNN`: Base class of RNN. It accepts an RNN cell or a list of RNN cells, and iterate on the sequence to convert the input as an RNN through the calling of `tf.keras.backend.rnn` function.\n",
    "\n",
    "* `LSTMCell`: LSTM cell. Unlike iterating across the whole sequence as `LSTM`, it only iterate once on the sequence. It would be more intuitive to understand the LSTM equals to `LSTMCell` wrapped by the base layer `RNN`.\n",
    "\n",
    "* `GRUCell`: GRU cell. Unlike iterating across the whole sequence as `GRU`, it only iterate once on the sequence.\n",
    "\n",
    "* `SimpleRNNCell`: SimpleRNN cell. Unlike iterating across the whole sequence as `SimpleRNN`, it only iterate once on the sequence.\n",
    "\n",
    "* `AbstractRNNCell`: Abstract RNN Cell. It allows user to customize RNN cell through inheritance and subsequently construct the RNN layer through wrapping these RNN cells by RNN base layer.\n",
    "\n",
    "* `Attention`: Dot-product attention layer, a.k.a. Luong-style attention, for constructing attention model.\n",
    "\n",
    "* `AdditiveAttention`: Additive attention layer, a.k.a. Bahdanau-style attention, for constructing attention model.\n",
    "\n",
    "* `TimeDistributed`: Time distributed wrapper, allows applying `Dense`, `Conv2D` to each time segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Customized Model Layer\n",
    "\n",
    "\n",
    "It is recommended to use `Lambda` layer for customized model layer without trainable parameter.\n",
    "\n",
    "For the customized model layer with trainable parameters, it is recommended to inherite from the base class `Layer`.\n",
    "\n",
    "We only need to define forward propagation for `Lambda` layer since there is no trainable parameter, thus it is easier in application comparing to the inheritance from base class `Layer`.\n",
    "\n",
    "The forward propagation of `Lambda` layer could be expressed using `lambda` function or keyword `def` in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 0,  1,  4,  9, 16], dtype=int32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models,regularizers\n",
    "\n",
    "mypower = layers.Lambda(lambda x:tf.math.pow(x,2))\n",
    "mypower(tf.range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inheriting from `Layer` needs re-implementation of the initialization, `build`and `call` methods. Here is an example of simplified linear layer, which is similar to `Dense`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(Linear, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    \n",
    "    # The trainable parameters are defined in build method\n",
    "    def build(self, input_shape): \n",
    "        self.w = self.add_weight(\"w\",shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True) # Parameter named \"w\" is compulsory or an error will be thrown out\n",
    "        self.b = self.add_weight(\"b\",shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        super(Linear,self).build(input_shape) # Identical to self.built = True\n",
    "\n",
    "    # The logic of forward propagation is defined in call method, and is called by __call__ method\n",
    "    @tf.function\n",
    "    def call(self, inputs): \n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "    # Use customized get-config method to save the model as h5 format, specifically for the model composed through Functional API with customized Layer\n",
    "    def get_config(self):  \n",
    "        config = super(Linear, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(units = 8)\n",
    "print(linear.built)\n",
    "# Specify input_shape, call build method; the 0th dimension is for the number of samples, should be filled with None.\n",
    "linear.build(input_shape = (None,16)) \n",
    "print(linear.built)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(None, 8)\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(units = 8)\n",
    "print(linear.built)\n",
    "linear.build(input_shape = (None,16)) \n",
    "print(linear.compute_output_shape(input_shape = (None,16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "{'name': 'linear_2', 'trainable': True, 'dtype': 'float32', 'units': 16}\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(units = 16)\n",
    "print(linear.built)\n",
    "# If built = False, the __call__ method will call \"build\" method first, then call \"call\" method\n",
    "linear(tf.random.uniform((100,64))) \n",
    "print(linear.built)\n",
    "config = linear.get_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.input_shape:  (None, 2)\n",
      "model.output_shape:  (None, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "linear (Linear)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "# Note: the input_shape here will be modified by the model, so we don't have to fill None in the dimension representing the number of samples.\n",
    "model.add(Linear(units = 1,input_shape = (2,)))  \n",
    "print(\"model.input_shape: \",model.input_shape)\n",
    "print(\"model.output_shape: \",model.output_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11953548]\n",
      " [-0.2703896 ]]\n",
      "[[-0.11953548]\n",
      " [-0.2703896 ]]\n",
      "INFO:tensorflow:Assets written to: ./data/linear_model/assets\n",
      "[[-0.11953548]\n",
      " [-0.2703896 ]]\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = \"sgd\",loss = \"mse\",metrics=[\"mae\"])\n",
    "print(model.predict(tf.constant([[3.0,2.0],[4.0,5.0]])))\n",
    "\n",
    "\n",
    "# Save as h5 formatted model\n",
    "model.save(\"./data/linear_model.h5\",save_format = \"h5\")\n",
    "model_loaded_keras = tf.keras.models.load_model(\n",
    "    \"./data/linear_model.h5\",custom_objects={\"Linear\":Linear})\n",
    "print(model_loaded_keras.predict(tf.constant([[3.0,2.0],[4.0,5.0]])))\n",
    "\n",
    "\n",
    "# Save as tf formatted model\n",
    "model.save(\"./data/linear_model\",save_format = \"tf\")\n",
    "model_loaded_tf = tf.keras.models.load_model(\"./data/linear_model\")\n",
    "print(model_loaded_tf.predict(tf.constant([[3.0,2.0],[4.0,5.0]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
