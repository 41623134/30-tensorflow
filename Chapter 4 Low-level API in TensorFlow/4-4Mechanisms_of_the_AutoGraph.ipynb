{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-4 Mechanisms of the AutoGraph\n",
    "\n",
    "There are three ways of constructing graph: static, dynamic and Autograph.\n",
    "\n",
    "TensorFlow 2.X uses dynamic graph and Autograph.\n",
    "\n",
    "Dynamic graph is easier for debugging with higher encoding efficiency, but with lower efficiency in execution.\n",
    "\n",
    "Static graph has high efficiency in execution, but more difficult for debugging.\n",
    "\n",
    "Autograph mechanism transforms dynamic graph into static graph, making allowance for both executing and encoding efficiencies.\n",
    "\n",
    "There are certain rules for the code that is able to converted by Autograph, or it could result in failure or unexpected results.\n",
    "\n",
    "We are going to introduce the coding rules of Autograph and its mechanism of converting into static graph, together with introduction about how to construct Autograph using `tf.Module`.\n",
    "\n",
    "The coding rules of Autograph was introduced in the last section. Here we introduce the mechanisms of Autograph.\n",
    "\n",
    "\n",
    "\n",
    "### 1. Mechanisms of Autograph\n",
    "\n",
    "\n",
    "**What happens when we define a function using decorator `@tf.function` ?**\n",
    "\n",
    "Consider the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "\n",
    "@tf.function(autograph=True)\n",
    "def myadd(a,b):\n",
    "    for i in tf.range(3):\n",
    "        tf.print(i)\n",
    "    c = a+b\n",
    "    print(\"tracing\")\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing happens except a function signature is recorded in the stack of Python.\n",
    "\n",
    "**What happens when this function decorated by `@tf.function` is called?**\n",
    "\n",
    "Consider the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracing\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'helloworld'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myadd(tf.constant(\"hello\"),tf.constant(\"world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #region -->\n",
    "There are two incidents:\n",
    "\n",
    "First, the graph is created.\n",
    "\n",
    "A static graph is created. The Python code inside this function is executed, the tensor type of each variable is determined, and the operator is added to the graph according to the order of execution. During this period, if the argument autograph=True (default) is setted, convertting of the controlling flow in Python to the one inside TensorFlow graph will happen. The majority of the work are: replacing `if` to `tf.cond` operator; replacing `while` and `for` looping to `tf.while_loop`; when necessary, add `tf.control_dependencies` to specify the dependencies of executing orders.\n",
    "\n",
    "This is identical to the following expressions in TensorFlow 1.X:\n",
    "\n",
    "```python\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    a = tf.placeholder(shape=[],dtype=tf.string)\n",
    "    b = tf.placeholder(shape=[],dtype=tf.string)\n",
    "    cond = lambda i: i<tf.constant(3)\n",
    "    def body(i):\n",
    "        tf.print(i)\n",
    "        return(i+1)\n",
    "    loop = tf.while_loop(cond,body,loop_vars=[0])\n",
    "    loop\n",
    "    with tf.control_dependencies(loop):\n",
    "        c = tf.strings.join([a,b])\n",
    "    print(\"tracing\")\n",
    "```\n",
    "\n",
    "The second incident is the execution of the graph.\n",
    "\n",
    "This is identical to the following expressions in TensorFlow 1.X:\n",
    "\n",
    "```python\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(c,feed_dict={a:tf.constant(\"hello\"),b:tf.constant(\"world\")})\n",
    "```\n",
    "\n",
    "So the result for the first step comes first: A string \"tracing\" printed by the standard I/O stream of Python.\n",
    "\n",
    "And next is the result of the second step: A string \"1, 2, 3\" printed by the standard I/O stream of TensorFlow.\n",
    "\n",
    "<!-- #endregion -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is going to happen when we call this function again with the same types of the input arguments?**\n",
    "\n",
    "Consider the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The second incident is the execution of the graph.\n",
    "\n",
    "This is identical to the following expressions in TensorFlow 1.X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'goodmorning'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myadd(tf.constant(\"good\"),tf.constant(\"morning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data type of the argument has been changed, the previously created graph cannot be used again.\n",
    "\n",
    "Two more tasks to be done: create new graph and execute it.\n",
    "\n",
    "The result of the first step will be observed again, i.e. a string \"tracing\" printed by the standard I/O stream of Python.\n",
    "\n",
    "And next is the result of the second step: A string \"1, 2, 3\" printed by the standard I/O stream of TensorFlow.\n",
    "\n",
    "\n",
    "**Note: if the data type of the argument is not Tensor in the original definition of this function, then the graph will be re-created each time after calling this function.**\n",
    "\n",
    "The demonstrated code below re-creates graph every time, so it is recommended to use Tensor type as the arguments when calling the function decorated by `@tf.function`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracing\n",
      "0\n",
      "1\n",
      "2\n",
      "tracing\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'goodmorning'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myadd(\"hello\",\"world\")\n",
    "myadd(\"good\",\"morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scrutinize the Coding Rules of Autograph Again\n",
    "\n",
    "\n",
    "We can have a better understanding to the three rules of coding of Autograph after knowing the mechanisms above.\n",
    "\n",
    "1, We should use the TensorFlow-defined functions to be decorated by `@tf.function` as much as possible, instead of those Python functions. For instance, `tf.print` should be used instead of `print`.\n",
    "\n",
    "Explanations: Python functions are only used during the stage of creating static graph. The Python functions are not able to be embedded into the static graph, so these Python functions are not calculated during the calling after the graph creation; in contrast, TensorFlow functions are able to be embedded into the graph. Using Python functions is causing unmatched outputs between the \"eager execution\" before the decoration by `@tf.function` and the \"execution of static graph\" after the decoration by `@tf.function`.\n",
    "\n",
    "2，Avoid defining `tf.Variable` inside the decorator `@tf.function`.\n",
    "\n",
    "Explanations: The defined `tf.Variable` will be re-created every time when calling the function during the \"eager execution\" stage. However, this re-creation of `tf.Variable` only takes place at the first step, i.e. tracing Python code to create the graph, which is introducing unmatched outputs between the \"eager execution\" before the decoration by `@tf.function` and the \"execution of static graph\" after the decoration by `@tf.function`. In fact, TensorFlow throws error in most of such cases.\n",
    "\n",
    "3，Functions that are decorated by `@tf.function` cannot modify the variables outside the function with the data types such as Python list, dictionary, etc.\n",
    "\n",
    "Explanations: Static graph is executed in the TensorFlow kernels, which are compiled from C++ code, thus the list and dictionary in Python are not able to be embedded into the graph. These data types can only be read during the stage of graph creating and cannot be modified during the graph execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
